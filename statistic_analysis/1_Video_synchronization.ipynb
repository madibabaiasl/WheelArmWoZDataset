{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **Video Time Length Correction**\n",
        "\n",
        "This section is only to correct fps to generate videos in the same time length."
      ],
      "metadata": {
        "id": "YfosK8VebB4T"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#!/usr/bin/env python3\n",
        "import os\n",
        "import cv2\n",
        "import bisect\n",
        "import math\n",
        "import pickle\n",
        "from typing import List, Tuple\n",
        "\n",
        "# -----------------------------\n",
        "# Config\n",
        "# -----------------------------\n",
        "INPUTS = [\n",
        "    (\"cam_0_rgb_video.avi\", \"cam_0_rgb_video.metadata\", \"cam_0_synced_ref_fps.mp4\", 12.0),\n",
        "    (\"cam_2_rgb_video.avi\", \"cam_2_rgb_video.metadata\", \"cam_2_synced_ref_fps.mp4\", 15.0),\n",
        "]\n",
        "\n",
        "# Reference time grid follows slowest fps\n",
        "REF_FPS = min(fps for _, _, _, fps in INPUTS)\n",
        "\n",
        "# Matching threshold (seconds)\n",
        "THRESH_MS = 33.0\n",
        "THRESH_S = THRESH_MS / 1000.0\n",
        "\n",
        "\n",
        "# -----------------------------\n",
        "# Helpers\n",
        "# -----------------------------\n",
        "def load_timestamps(meta_path: str) -> List[float]:\n",
        "    with open(meta_path, \"rb\") as f:\n",
        "        md = pickle.load(f)\n",
        "    if isinstance(md, dict):\n",
        "        if \"timestamps\" in md:\n",
        "            ts = md[\"timestamps\"]\n",
        "        elif \"ts\" in md:\n",
        "            ts = md[\"ts\"]\n",
        "        else:\n",
        "            raise KeyError(f\"{meta_path}: no 'timestamps' or 'ts' key\")\n",
        "    elif isinstance(md, list):\n",
        "        ts = md\n",
        "    else:\n",
        "        raise ValueError(f\"{meta_path}: unsupported metadata type {type(md)}\")\n",
        "\n",
        "    if len(ts) < 2:\n",
        "        raise ValueError(f\"{meta_path}: not enough timestamps\")\n",
        "\n",
        "    a = 1765330347.4231\n",
        "    span = ts[-1] - ts[0]\n",
        "    if span > 1e10:     # nanoseconds -> seconds\n",
        "        return [t / 1e9 for t in ts]\n",
        "    elif span > 1e4:    # milliseconds -> seconds\n",
        "        return [t / 1e3 for t in ts]\n",
        "    else:               # already seconds\n",
        "        return ts\n",
        "\n",
        "def make_grid(start_t: float, duration_s_int: int, fps: float) -> List[float]:\n",
        "    n = int(duration_s_int * fps)\n",
        "    step = 1.0 / fps\n",
        "    return [start_t + i * step for i in range(n)]\n",
        "\n",
        "def pick_closest_index(ts: List[float], target_t: float, lo: int, hi: int) -> Tuple[int, float]:\n",
        "    \"\"\"Closest index to target_t within ts[lo:hi] (hi exclusive).\"\"\"\n",
        "    if hi <= lo:\n",
        "        return -1, float(\"inf\")\n",
        "\n",
        "    i = bisect.bisect_left(ts, target_t, lo, hi)\n",
        "\n",
        "    cand = []\n",
        "    if i > lo:\n",
        "        cand.append((i - 1, abs(ts[i - 1] - target_t)))\n",
        "    if i < hi:\n",
        "        cand.append((i, abs(ts[i] - target_t)))\n",
        "\n",
        "    if not cand:\n",
        "        return -1, float(\"inf\")\n",
        "    return min(cand, key=lambda p: p[1])\n",
        "\n",
        "def open_writer_like(cap: cv2.VideoCapture, out_path: str, fps: float):\n",
        "    W = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
        "    H = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
        "    fourcc = cv2.VideoWriter_fourcc(*\"mp4v\")\n",
        "    writer = cv2.VideoWriter(out_path, fourcc, fps, (W, H))\n",
        "    if not writer.isOpened():\n",
        "        raise RuntimeError(f\"Failed to open VideoWriter for {out_path}\")\n",
        "    return writer\n",
        "\n",
        "\n",
        "# -----------------------------\n",
        "# Main\n",
        "# -----------------------------\n",
        "def main():\n",
        "    # 1) Load streams\n",
        "    streams = []\n",
        "    for vid, meta, out, fps in INPUTS:\n",
        "        if not os.path.exists(vid):\n",
        "            raise FileNotFoundError(f\"Video not found: {vid}\")\n",
        "        if not os.path.exists(meta):\n",
        "            raise FileNotFoundError(f\"Metadata not found: {meta}\")\n",
        "        ts = load_timestamps(meta)\n",
        "        streams.append({\"video\": vid, \"meta\": meta, \"out\": out, \"fps\": fps, \"ts\": ts})\n",
        "\n",
        "    # 2) Overlap window\n",
        "    overlap_start = max(s[\"ts\"][0] for s in streams)\n",
        "    overlap_end   = min(s[\"ts\"][-1] for s in streams)\n",
        "    if overlap_end <= overlap_start:\n",
        "        raise ValueError(\"No temporal overlap between streams.\")\n",
        "\n",
        "    duration_int = int(math.floor(overlap_end - overlap_start))\n",
        "    if duration_int < 1:\n",
        "        raise ValueError(\"Overlap < 1 second; nothing to sync.\")\n",
        "\n",
        "    # 3) Reference grid (slow fps)\n",
        "    ref_grid = make_grid(overlap_start, duration_int, REF_FPS)\n",
        "    print(f\"Overlap: [{overlap_start:.6f}, {overlap_end:.6f}] duration_int={duration_int}s\")\n",
        "    print(f\"REF_FPS={REF_FPS} ref_frames={len(ref_grid)} THRESH={THRESH_MS:.1f}ms\")\n",
        "\n",
        "    # 4) Trim each stream to overlap & build indices to write (one output frame per ref_grid time)\n",
        "    for s in streams:\n",
        "        ts = s[\"ts\"]\n",
        "        lo = bisect.bisect_left(ts, overlap_start)\n",
        "        hi = bisect.bisect_right(ts, overlap_start + duration_int)\n",
        "        s[\"trim_lo\"], s[\"trim_hi\"] = lo, hi\n",
        "\n",
        "        write_indices = []\n",
        "        last_good = lo if lo < hi else 0\n",
        "\n",
        "        for t in ref_grid:\n",
        "            idx, diff = pick_closest_index(ts, t, lo, hi)\n",
        "            if idx >= 0 and diff <= THRESH_S:\n",
        "                last_good = idx\n",
        "            # hold-last if no match\n",
        "            write_indices.append(last_good)\n",
        "\n",
        "        s[\"write_indices\"] = write_indices\n",
        "        print(f\"{s['out']}: will write {len(write_indices)} frames at {REF_FPS} FPS\")\n",
        "\n",
        "    # 5) Write videos (both at REF_FPS so frame k aligns across videos)\n",
        "    for s in streams:\n",
        "        cap = cv2.VideoCapture(s[\"video\"])\n",
        "        if not cap.isOpened():\n",
        "            raise RuntimeError(f\"Failed to open {s['video']}\")\n",
        "        writer = open_writer_like(cap, s[\"out\"], REF_FPS)\n",
        "\n",
        "        prev = -1\n",
        "        for idx in s[\"write_indices\"]:\n",
        "            if idx != prev:\n",
        "                cap.set(cv2.CAP_PROP_POS_FRAMES, idx)\n",
        "            ok, frame = cap.read()\n",
        "            if not ok:\n",
        "                # fallback: try previous\n",
        "                if prev >= 0:\n",
        "                    cap.set(cv2.CAP_PROP_POS_FRAMES, prev)\n",
        "                    ok, frame = cap.read()\n",
        "                if not ok:\n",
        "                    print(f\"Warning: failed to read frame {idx} for {s['out']}; stopping.\")\n",
        "                    break\n",
        "            writer.write(frame)\n",
        "            prev = idx\n",
        "\n",
        "        writer.release()\n",
        "        cap.release()\n",
        "        print(f\"Wrote: {s['out']} at {REF_FPS} FPS\")\n",
        "\n",
        "    print(\"Done.\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VNcRijVTFyVp",
        "outputId": "bb7b1c94-6d88-4555-8dfa-17fe7b857623"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overlap: [1765411790.435866, 1765411945.703777] duration_int=155s\n",
            "REF_FPS=12.0 ref_frames=1860 THRESH=33.0ms\n",
            "cam_0_synced_ref_fps.mp4: will write 1860 frames at 12.0 FPS\n",
            "cam_2_synced_ref_fps.mp4: will write 1860 frames at 12.0 FPS\n",
            "Wrote: cam_0_synced_ref_fps.mp4 at 12.0 FPS\n",
            "Wrote: cam_2_synced_ref_fps.mp4 at 12.0 FPS\n",
            "Done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Synchronization**\n",
        "1. The reference start and end is confirmed by the overlap starting and ending time between the two videos and the timestamp follows the slow fps.\n",
        "2. Match frames from two videos in the threshold of 20ms."
      ],
      "metadata": {
        "id": "SlUOc1rlIUvv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#!/usr/bin/env python3\n",
        "import os\n",
        "import bisect\n",
        "import math\n",
        "import pickle\n",
        "import csv\n",
        "from typing import List, Tuple\n",
        "\n",
        "# -----------------------------\n",
        "# Config\n",
        "# -----------------------------\n",
        "INPUTS = [\n",
        "    (\"cam_0_rgb_video.avi\", \"cam_0_rgb_video.metadata\", 12.0),\n",
        "    (\"cam_2_rgb_video.avi\", \"cam_2_rgb_video.metadata\", 15.0),\n",
        "]\n",
        "\n",
        "REF_FPS = min(fps for _, _, fps in INPUTS)\n",
        "\n",
        "THRESH_MS = 33.0\n",
        "THRESH_S = THRESH_MS / 1000.0\n",
        "\n",
        "CSV_PATH = \"timestamps_synced_refgrid.csv\"\n",
        "\n",
        "# -----------------------------\n",
        "# Helpers\n",
        "# -----------------------------\n",
        "def load_timestamps(meta_path: str) -> List[float]:\n",
        "    with open(meta_path, \"rb\") as f:\n",
        "        md = pickle.load(f)\n",
        "    if isinstance(md, dict):\n",
        "        if \"timestamps\" in md:\n",
        "            ts = md[\"timestamps\"]\n",
        "        elif \"ts\" in md:\n",
        "            ts = md[\"ts\"]\n",
        "        else:\n",
        "            raise KeyError(f\"{meta_path}: no 'timestamps' or 'ts' key\")\n",
        "    elif isinstance(md, list):\n",
        "        ts = md\n",
        "    else:\n",
        "        raise ValueError(f\"{meta_path}: unsupported metadata type {type(md)}\")\n",
        "\n",
        "    if len(ts) < 2:\n",
        "        raise ValueError(f\"{meta_path}: not enough timestamps\")\n",
        "\n",
        "    span = ts[-1] - ts[0]\n",
        "    if span > 1e10:\n",
        "        return [t / 1e9 for t in ts]\n",
        "    elif span > 1e4:\n",
        "        return [t / 1e3 for t in ts]\n",
        "    else:\n",
        "        return ts\n",
        "\n",
        "def make_grid(start_t: float, duration_s_int: int, fps: float) -> List[float]:\n",
        "    n = int(duration_s_int * fps)\n",
        "    step = 1.0 / fps\n",
        "    return [start_t + i * step for i in range(n)]\n",
        "\n",
        "def pick_closest_index(ts: List[float], target_t: float, lo: int, hi: int) -> Tuple[int, float]:\n",
        "    if hi <= lo:\n",
        "        return -1, float(\"inf\")\n",
        "    i = bisect.bisect_left(ts, target_t, lo, hi)\n",
        "    cand = []\n",
        "    if i > lo:\n",
        "        cand.append((i - 1, abs(ts[i - 1] - target_t)))\n",
        "    if i < hi:\n",
        "        cand.append((i, abs(ts[i] - target_t)))\n",
        "    if not cand:\n",
        "        return -1, float(\"inf\")\n",
        "    return min(cand, key=lambda p: p[1])\n",
        "\n",
        "# -----------------------------\n",
        "# Main\n",
        "# -----------------------------\n",
        "def main():\n",
        "    streams = []\n",
        "    for vid, meta, fps in INPUTS:\n",
        "        if not os.path.exists(meta):\n",
        "            raise FileNotFoundError(f\"Metadata not found: {meta}\")\n",
        "        ts = load_timestamps(meta)\n",
        "        streams.append({\"video\": vid, \"meta\": meta, \"fps\": fps, \"ts\": ts})\n",
        "\n",
        "    overlap_start = max(s[\"ts\"][0] for s in streams)\n",
        "    overlap_end   = min(s[\"ts\"][-1] for s in streams)\n",
        "    if overlap_end <= overlap_start:\n",
        "        raise ValueError(\"No temporal overlap between streams.\")\n",
        "\n",
        "    duration_int = int(math.floor(overlap_end - overlap_start))\n",
        "    if duration_int < 1:\n",
        "        raise ValueError(\"Overlap < 1 second; nothing to sync.\")\n",
        "\n",
        "    ref_grid = make_grid(overlap_start, duration_int, REF_FPS)\n",
        "\n",
        "    # Trim + compute mapping\n",
        "    for s in streams:\n",
        "        ts = s[\"ts\"]\n",
        "        lo = bisect.bisect_left(ts, overlap_start)\n",
        "        hi = bisect.bisect_right(ts, overlap_start + duration_int)\n",
        "        s[\"trim_lo\"], s[\"trim_hi\"] = lo, hi\n",
        "\n",
        "        picked = []\n",
        "        last_good = lo if lo < hi else 0\n",
        "        for t in ref_grid:\n",
        "            idx, diff = pick_closest_index(ts, t, lo, hi)\n",
        "            if idx >= 0 and diff <= THRESH_S:\n",
        "                last_good = idx\n",
        "            picked.append((last_good, abs(ts[last_good] - t)))\n",
        "        s[\"picked\"] = picked\n",
        "\n",
        "    # Write CSV\n",
        "    header = [\"ref_frame_idx\", \"ref_time_s\"]\n",
        "    for i in [0,2]:\n",
        "        header += [f\"cam_{i}_picked_idx\", f\"cam_{i}_picked_ts_s\", f\"cam_{i}_abs_diff_s\"]\n",
        "\n",
        "    with open(CSV_PATH, \"w\", newline=\"\") as f:\n",
        "        w = csv.writer(f)\n",
        "        w.writerow(header)\n",
        "\n",
        "        for k, t in enumerate(ref_grid):\n",
        "            row = [k, f\"{t:.9f}\"]\n",
        "            for s in streams:\n",
        "                idx, diff = s[\"picked\"][k]\n",
        "                row += [idx, f\"{s['ts'][idx]:.9f}\", f\"{diff:.9f}\"]\n",
        "            w.writerow(row)\n",
        "\n",
        "    print(f\"Saved CSV: {CSV_PATH}\")\n",
        "    print(f\"Overlap: [{overlap_start:.6f}, {overlap_end:.6f}] duration_int={duration_int}s\")\n",
        "    print(f\"REF_FPS={REF_FPS} ref_frames={len(ref_grid)} THRESH={THRESH_MS:.1f}ms\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "92MtpTwsI3q9",
        "outputId": "282b3369-b7b7-4690-9e44-5bf602ed7056"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saved CSV: timestamps_synced_refgrid.csv\n",
            "Overlap: [1765061633.203466, 1765061791.083266] duration_int=157s\n",
            "REF_FPS=12.0 ref_frames=1884 THRESH=33.0ms\n"
          ]
        }
      ]
    }
  ]
}