{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "In this notebook, I first calculate the jerk the end effector and each joints on the WheelArm. If the value is high, I will go deeper into the movement period and do analysis."
      ],
      "metadata": {
        "id": "HgBDl3u3hfmb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#!/usr/bin/env python3\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import h5py\n",
        "from scipy.signal import butter, filtfilt\n",
        "\n",
        "JOINT_H5 = \"kinova_gen3_joint_states.h5\"\n",
        "EE_H5    = \"kinova_gen3_cartesian_states.h5\"\n",
        "\n",
        "OUT_EE   = \"filtered_ee.csv\"\n",
        "OUT_JOINTS = \"filtered_joints.csv\"\n",
        "\n",
        "# ---------- Filter settings ----------\n",
        "# Cutoff frequency in Hz (tune this!)\n",
        "CUTOFF_HZ = 5.0\n",
        "FILTER_ORDER = 4\n",
        "\n",
        "# Optional: cap resample rate if your timestamps are extremely dense/noisy\n",
        "MAX_RESAMPLE_HZ = 200.0  # set None to disable\n",
        "\n",
        "\n",
        "def dedup_by_time(t: np.ndarray, X: np.ndarray):\n",
        "    \"\"\"Average samples that share identical timestamps (avoids dt=0 issues).\"\"\"\n",
        "    t = np.asarray(t, dtype=np.float64)\n",
        "    X = np.asarray(X, dtype=np.float64)\n",
        "\n",
        "    order = np.argsort(t)\n",
        "    t = t[order]\n",
        "    X = X[order]\n",
        "\n",
        "    uniq, idx_start, counts = np.unique(t, return_index=True, return_counts=True)\n",
        "    out = np.zeros((len(uniq),) + X.shape[1:], dtype=np.float64)\n",
        "    for i, (s, c) in enumerate(zip(idx_start, counts)):\n",
        "        out[i] = X[s:s + c].mean(axis=0)\n",
        "    return uniq, out\n",
        "\n",
        "\n",
        "def make_uniform_grid(t: np.ndarray):\n",
        "    \"\"\"Create a uniform time grid using median dt.\"\"\"\n",
        "    dt = np.diff(t)\n",
        "    dt = dt[dt > 0]\n",
        "    if len(dt) < 5:\n",
        "        raise ValueError(\"Not enough valid dt samples to build a uniform grid.\")\n",
        "\n",
        "    dt_med = float(np.median(dt))\n",
        "    fs = 1.0 / dt_med\n",
        "\n",
        "    if MAX_RESAMPLE_HZ is not None and fs > MAX_RESAMPLE_HZ:\n",
        "        fs = MAX_RESAMPLE_HZ\n",
        "        dt_med = 1.0 / fs\n",
        "\n",
        "    t0, t1 = float(t[0]), float(t[-1])\n",
        "    N = int(np.floor((t1 - t0) / dt_med)) + 1\n",
        "    t_u = t0 + dt_med * np.arange(N, dtype=np.float64)\n",
        "    return t_u, fs\n",
        "\n",
        "\n",
        "def interp_to_grid(t_src: np.ndarray, X_src: np.ndarray, t_u: np.ndarray):\n",
        "    \"\"\"Linear interpolation of each column onto uniform grid.\"\"\"\n",
        "    X_src = np.asarray(X_src, dtype=np.float64)\n",
        "    if X_src.ndim == 1:\n",
        "        return np.interp(t_u, t_src, X_src)\n",
        "\n",
        "    X_u = np.zeros((len(t_u), X_src.shape[1]), dtype=np.float64)\n",
        "    for d in range(X_src.shape[1]):\n",
        "        X_u[:, d] = np.interp(t_u, t_src, X_src[:, d])\n",
        "    return X_u\n",
        "\n",
        "\n",
        "def lowpass_zero_phase(X: np.ndarray, fs: float, cutoff_hz: float, order: int):\n",
        "    \"\"\"\n",
        "    Zero-phase Butterworth low-pass via filtfilt.\n",
        "    Assumes uniform sampling at rate fs.\n",
        "    \"\"\"\n",
        "    if cutoff_hz <= 0 or cutoff_hz >= fs / 2:\n",
        "        raise ValueError(f\"cutoff_hz must be in (0, fs/2). Got cutoff={cutoff_hz}, fs={fs}\")\n",
        "\n",
        "    b, a = butter(order, cutoff_hz / (fs / 2), btype=\"low\")\n",
        "    X = np.asarray(X, dtype=np.float64)\n",
        "\n",
        "    if X.ndim == 1:\n",
        "        return filtfilt(b, a, X, axis=0)\n",
        "\n",
        "    return filtfilt(b, a, X, axis=0)\n",
        "\n",
        "\n",
        "def deriv_from_pos(t_u: np.ndarray, X_u: np.ndarray):\n",
        "    \"\"\"Compute velocity via numerical derivative on uniform grid.\"\"\"\n",
        "    return np.gradient(X_u, t_u, axis=0, edge_order=2)\n",
        "\n",
        "\n",
        "def main():\n",
        "    # --------- Load EE ---------\n",
        "    with h5py.File(EE_H5, \"r\") as f:\n",
        "        t_ee = f[\"timestamps\"][...]\n",
        "        p_ee = f[\"positions\"][...]   # (N,3)\n",
        "\n",
        "    t_ee, p_ee = dedup_by_time(t_ee, p_ee)\n",
        "    t_u_ee, fs_ee = make_uniform_grid(t_ee)\n",
        "    p_u = interp_to_grid(t_ee, p_ee, t_u_ee)\n",
        "\n",
        "    p_f = lowpass_zero_phase(p_u, fs=fs_ee, cutoff_hz=CUTOFF_HZ, order=FILTER_ORDER)\n",
        "    v_f = deriv_from_pos(t_u_ee, p_f)  # filtered velocity derived from filtered pos\n",
        "\n",
        "    df_ee = pd.DataFrame({\n",
        "        \"t\": t_u_ee,\n",
        "        \"x\": p_f[:, 0], \"y\": p_f[:, 1], \"z\": p_f[:, 2],\n",
        "        \"vx\": v_f[:, 0], \"vy\": v_f[:, 1], \"vz\": v_f[:, 2],\n",
        "    })\n",
        "    df_ee.to_csv(OUT_EE, index=False)\n",
        "    print(f\"Saved {OUT_EE}  (fs≈{fs_ee:.2f} Hz, cutoff={CUTOFF_HZ} Hz, order={FILTER_ORDER})\")\n",
        "\n",
        "    # --------- Load joints ---------\n",
        "    with h5py.File(JOINT_H5, \"r\") as f:\n",
        "        t_q = f[\"timestamps\"][...]\n",
        "        q   = f[\"positions\"][...]    # (N,7)\n",
        "        dq  = f[\"velocitys\"][...]    # (N,7)  (note: dataset name is 'velocitys' in your file)\n",
        "\n",
        "    t_q, q = dedup_by_time(t_q, q)\n",
        "    _, dq = dedup_by_time(t_q, dq)   # same t_q keys in your file, but keep consistent\n",
        "\n",
        "    t_u_q, fs_q = make_uniform_grid(t_q)\n",
        "    q_u  = interp_to_grid(t_q, q,  t_u_q)\n",
        "    dq_u = interp_to_grid(t_q, dq, t_u_q)\n",
        "\n",
        "    # Filter joint positions + (optionally) joint velocities\n",
        "    q_f  = lowpass_zero_phase(q_u,  fs=fs_q, cutoff_hz=CUTOFF_HZ, order=FILTER_ORDER)\n",
        "\n",
        "    # Recommended: compute dq from filtered q (more consistent)\n",
        "    dq_from_q_f = deriv_from_pos(t_u_q, q_f)\n",
        "\n",
        "    # If you want to also filter the logged dq, uncomment:\n",
        "    # dq_f = lowpass_zero_phase(dq_u, fs=fs_q, cutoff_hz=CUTOFF_HZ, order=FILTER_ORDER)\n",
        "    # and then choose dq_f vs dq_from_q_f below.\n",
        "\n",
        "    data = {\"t\": t_u_q}\n",
        "    for j in range(q_f.shape[1]):\n",
        "        data[f\"q{j+1}\"]  = q_f[:, j]\n",
        "    for j in range(dq_from_q_f.shape[1]):\n",
        "        data[f\"dq{j+1}\"] = dq_from_q_f[:, j]\n",
        "\n",
        "    df_j = pd.DataFrame(data)\n",
        "    df_j.to_csv(OUT_JOINTS, index=False)\n",
        "    print(f\"Saved {OUT_JOINTS} (fs≈{fs_q:.2f} Hz, cutoff={CUTOFF_HZ} Hz, order={FILTER_ORDER})\")\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CcwoC_-WmUqk",
        "outputId": "176fa6f0-7f14-46b1-8512-af9b70c7075f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saved filtered_ee.csv  (fs≈10.47 Hz, cutoff=5.0 Hz, order=4)\n",
            "Saved filtered_joints.csv (fs≈20.00 Hz, cutoff=5.0 Hz, order=4)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "This step is to calculate jerk based on filtered data and draw the jerk plot in time series."
      ],
      "metadata": {
        "id": "Qtcvtb34mv7F"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#!/usr/bin/env python3\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "EE_CSV = \"filtered_ee.csv\"\n",
        "\n",
        "OUT_EE_TS = \"ee_jerk_timeseries.csv\"\n",
        "OUT_EE_PLOT = \"ee_jerk_plot.png\"\n",
        "OUT_EE_STATS = \"ee_jerk_stats.csv\"\n",
        "\n",
        "\n",
        "def _ensure_strictly_increasing(t, *arrays):\n",
        "    \"\"\"Drop non-increasing timestamps (rare after filtering, but safe).\"\"\"\n",
        "    t = np.asarray(t, dtype=np.float64)\n",
        "    keep = np.ones_like(t, dtype=bool)\n",
        "    keep[1:] = np.diff(t) > 0\n",
        "    t2 = t[keep]\n",
        "    out = [np.asarray(a)[keep] for a in arrays]\n",
        "    return (t2, *out)\n",
        "\n",
        "\n",
        "def jerk_from_velocity(t, v):\n",
        "    \"\"\"\n",
        "    Given velocity v(t), compute:\n",
        "      a = dv/dt\n",
        "      j = da/dt\n",
        "    Works for vector v shape (N,3).\n",
        "    \"\"\"\n",
        "    a = np.gradient(v, t, axis=0, edge_order=2)\n",
        "    j = np.gradient(a, t, axis=0, edge_order=2)\n",
        "    return a, j\n",
        "\n",
        "\n",
        "def normalized_jerk_from_jerk(t, pos, jerk):\n",
        "    \"\"\"\n",
        "    Jnorm = (T^5 / L^2) * ∫ ||jerk||^2 dt\n",
        "    L is path length from pos.\n",
        "    \"\"\"\n",
        "    t = np.asarray(t, dtype=np.float64)\n",
        "    T = float(t[-1] - t[0])\n",
        "\n",
        "    # pos is (N,3)\n",
        "    L = float(np.sum(np.linalg.norm(np.diff(pos, axis=0), axis=1)))\n",
        "    jerk_sq = np.sum(jerk * jerk, axis=1)\n",
        "\n",
        "    E = float(np.trapz(jerk_sq, t))\n",
        "    Jnorm = (T**5 / (L**2)) * E if (T > 0 and L > 0) else np.nan\n",
        "    return Jnorm, T, L, E\n",
        "\n",
        "\n",
        "def main():\n",
        "    # =======================\n",
        "    # End-effector (translation)\n",
        "    # =======================\n",
        "    ee = pd.read_csv(EE_CSV)\n",
        "    t = ee[\"t\"].to_numpy()\n",
        "    p = ee[[\"x\", \"y\", \"z\"]].to_numpy()\n",
        "    v = ee[[\"vx\", \"vy\", \"vz\"]].to_numpy()\n",
        "\n",
        "    t, p, v = _ensure_strictly_increasing(t, p, v)\n",
        "\n",
        "    _, j = jerk_from_velocity(t, v)\n",
        "    jerk_mag = np.linalg.norm(j, axis=1)\n",
        "    jerk_sq = np.sum(j * j, axis=1)\n",
        "\n",
        "    # Normalized jerk\n",
        "    Jnorm_ee, T_ee, L_ee, E_ee = normalized_jerk_from_jerk(t, p, j)\n",
        "\n",
        "    # Mean / max jerk magnitude\n",
        "    mean_jerk = float(np.mean(jerk_mag))\n",
        "    max_jerk = float(np.max(jerk_mag))\n",
        "\n",
        "    # Save time series\n",
        "    ee_out = pd.DataFrame({\n",
        "        \"t\": t,\n",
        "        \"jx\": j[:, 0], \"jy\": j[:, 1], \"jz\": j[:, 2],\n",
        "        \"jerk_mag\": jerk_mag,\n",
        "        \"jerk_sq\": jerk_sq,\n",
        "    })\n",
        "    ee_out.to_csv(OUT_EE_TS, index=False)\n",
        "\n",
        "    # Plot jerk magnitude vs time\n",
        "    plt.figure()\n",
        "    plt.plot(t, jerk_mag)\n",
        "    plt.xlabel(\"t (s)\")\n",
        "    plt.ylabel(\"EE jerk magnitude (m/s^3)\")\n",
        "    plt.title(\"End-effector jerk vs time\")\n",
        "    plt.tight_layout()\n",
        "    plt.savefig(OUT_EE_PLOT, dpi=200)\n",
        "    plt.close()\n",
        "\n",
        "    # Save summary stats\n",
        "    stats = pd.DataFrame([{\n",
        "        \"Jnorm_end_effector_translation\": Jnorm_ee,\n",
        "        \"T_s\": T_ee,\n",
        "        \"L_m\": L_ee,\n",
        "        \"jerk_energy_int\": E_ee,\n",
        "        \"mean_jerk_mag_mps3\": mean_jerk,\n",
        "        \"max_jerk_mag_mps3\": max_jerk,\n",
        "        \"mean_jerk_sq\": float(np.mean(jerk_sq)),\n",
        "        \"max_jerk_sq\": float(np.max(jerk_sq)),\n",
        "    }])\n",
        "    stats.to_csv(OUT_EE_STATS, index=False)\n",
        "\n",
        "    print(\"Done.\")\n",
        "    print(f\"Jnorm={Jnorm_ee:.6e}, T={T_ee:.3f}s, L={L_ee:.6f}m\")\n",
        "    print(f\"mean jerk magnitude={mean_jerk:.6e} m/s^3\")\n",
        "    print(f\"max  jerk magnitude={max_jerk:.6e} m/s^3\")\n",
        "    print(f\"Saved: {OUT_EE_TS}, {OUT_EE_PLOT}, {OUT_EE_STATS}\")\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n"
      ],
      "metadata": {
        "id": "zt-8Idb9m2SD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5c198296-91bb-4e66-b73e-4c9e75aa78ab"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2057419789.py:47: DeprecationWarning: `trapz` is deprecated. Use `trapezoid` instead, or one of the numerical integration functions in `scipy.integrate`.\n",
            "  E = float(np.trapz(jerk_sq, t))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Done.\n",
            "Jnorm=4.311933e+10, T=155.904s, L=2.186122m\n",
            "mean jerk magnitude=9.079415e-02 m/s^3\n",
            "max  jerk magnitude=4.194219e-01 m/s^3\n",
            "Saved: ee_jerk_timeseries.csv, ee_jerk_plot.png, ee_jerk_stats.csv\n"
          ]
        }
      ]
    }
  ]
}